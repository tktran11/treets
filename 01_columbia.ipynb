{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5783d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp columbia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e67cae8",
   "metadata": {},
   "source": [
    "# Columbia data food analysis\n",
    "\n",
    "> Process collected food logging data specific to the columbia study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978e216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ca87f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import public_data_food_analysis_3.core as pdfa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6817542f",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c5086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_logging_data(folder_path):\n",
    "    \"\"\"\n",
    "    Description:\\n\n",
    "        This function reads all csv files in the folder_path folder into one dataframe. The files should be in csv format and the name of each file should start with 'yrt' and contain '_food_data' in the middle. For example, yrt1999_food_data123.csv is a valid file name that would be read into the dataframe if it exists in the folder_path folder. \n",
    "    \n",
    "    Input:\\n\n",
    "        - folder_path(string) : path to the folder that contain the data.\n",
    "    \n",
    "    Output:\\n\n",
    "        - a dataframe contains all the csv files in the folder given.\n",
    "        \n",
    "    \"\"\"\n",
    "    data_lst = glob.glob('{}/yrt*_food_data*.csv'.format(folder_path))\n",
    "    dfs = []\n",
    "    for x in data_lst:\n",
    "        dfs.append(pd.read_csv(x))\n",
    "    df = pd.concat(dfs)\n",
    "    return df.reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864a2159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>original_logtime</th>\n",
       "      <th>desc_text</th>\n",
       "      <th>food_type</th>\n",
       "      <th>PID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-12 02:30:00 +0000</td>\n",
       "      <td>milk</td>\n",
       "      <td>b</td>\n",
       "      <td>yrt1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-12 02:45:00 +0000</td>\n",
       "      <td>some medication</td>\n",
       "      <td>m</td>\n",
       "      <td>yrt1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           original_logtime        desc_text food_type      PID\n",
       "0           0  2021-05-12 02:30:00 +0000             milk         b  yrt1999\n",
       "1           1  2021-05-12 02:45:00 +0000  some medication         m  yrt1999"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_logging_data('data/col_test_data')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be6f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_phase_duration(df):\n",
    "    \"\"\"\n",
    "    Description:\\n\n",
    "        This is a function that calculates how many days each phase in the study took. Result includes the start and end date for that phase.\n",
    "    \n",
    "    Input:\\n\n",
    "        - df(pandas df) : information dataframe that contains columns: Start_Day, End_day\n",
    "    \n",
    "    Output:\\n\n",
    "        - a dataframe contains the phase_duration column.\n",
    "        \n",
    "    Requirement:\\n\n",
    "        - 'Start_day' and 'End_day' column existed in the df.\n",
    "    \"\"\"\n",
    "    df['phase_duration'] = df['End_day'] - df['Start_Day']+ pd.Timedelta(\"1 days\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a9526d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  phase_duration\n",
       "0         3 days\n",
       "1         4 days\n",
       "2         3 days\n",
       "3         4 days\n",
       "4            NaT"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_phase_duration(pd.read_excel('data/col_test_data/toy_data_17May2021.xlsx'))[['phase_duration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d32b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def count_caloric_entries(df, start_date='not_defined', end_date='not_defined'):\n",
    "    \"\"\"\n",
    "    Description:\\n\n",
    "        This is a function that counts the number of food and beverage loggings.\n",
    "    \n",
    "    Input:\\n\n",
    "        - df(pandas df) : food_logging data.\n",
    "        - start_date(datetime.date object) : start date of the period of counting. If not defined, it will be automatically set to be the earliest date in df. \n",
    "        - end_date(datetime.date object) : end date of the period of counting. If not defined, it will be automatically set to be the latest date in df.\n",
    "    \n",
    "    Output:\\n\n",
    "        - a float representing the number of caloric entries.\n",
    "        \n",
    "    Requirement:\\n\n",
    "        - 'date' column existed in the df.\n",
    "    \"\"\"\n",
    "    if pd.isnull(start_date) or pd.isnull(end_date):\n",
    "        return np.nan\n",
    "    if start_date=='not_defined':\n",
    "        start_date = df['date'].min()\n",
    "    if end_date=='not_defined':\n",
    "        end_date = df['date'].max()\n",
    "    df = df[(df['date']>=start_date) & (df['date']<=end_date)]\n",
    "    return df[df['food_type'].isin(['f','b'])].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f102c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the date\n",
    "df['original_logtime'] = pd.to_datetime(df['original_logtime'])\n",
    "df['date'] = pdfa.find_date(df, 'original_logtime', h=4)\n",
    "ref_tbl = pd.read_excel('data/col_test_data/toy_data_17May2021.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b3532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caloric_entries(df, ref_tbl['Start_Day'].iloc[0], ref_tbl['End_day'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd05fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mean_daily_eating_duration(df, time_col, start_date='not_defined', end_date='not_defined'):\n",
    "    \"\"\"\n",
    "    Description:\\n\n",
    "        This is a function that calculates the mean daily eating window, which is defined as the duration of first and last caloric intake.\n",
    "    \n",
    "    Input:\\n\n",
    "        - df(pandas df) : food_logging data.\n",
    "        - time_col(column existed in df, string) : contains the float time data for each logging.\n",
    "        - start_date(datetime.date object) : start date of the period of calculation. If not defined, it will be automatically set to be the earliest date in df. \n",
    "        - end_date(datetime.date object) : end date of the period of calculation. If not defined, it will be automatically set to be the latest date in df.\n",
    "    \n",
    "    Output:\\n\n",
    "        - a float representing the mean daily eating window.\n",
    "        \n",
    "    Requirement:\\n\n",
    "        - 'date' column existed in the df.\n",
    "        - float time is calculated.\n",
    "        \n",
    "    Optional functions to use to have proper inputs:\n",
    "        - find_date() for date_col\n",
    "        - find_float_time() for time_col\n",
    "    \"\"\"\n",
    "    if pd.isnull(start_date) or pd.isnull(end_date):\n",
    "        return np.nan\n",
    "    if start_date=='not_defined':\n",
    "        start_date = df['date'].min()\n",
    "    if end_date=='not_defined':\n",
    "        end_date = df['date'].max()\n",
    "    df = df[(df['date']>=start_date) & (df['date']<=end_date)]\n",
    "    df = df[df['food_type'].isin(['f','b'])]\n",
    "    breakfast_time = df.groupby('date').agg(min)\n",
    "    dinner_time = df.groupby('date').agg(max)\n",
    "    return (dinner_time[time_col]-breakfast_time[time_col]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f716d18",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f6b84d8216e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# float time and date columns are required for this function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'float_time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdfa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_float_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'original_logtime'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdfa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'original_logtime'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmean_daily_eating_duration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'float_time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_tbl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Start_Day'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_tbl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'End_day'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# float time and date columns are required for this function\n",
    "df['float_time'] = pdfa.find_float_time(df, 'original_logtime', h=4)\n",
    "df['date'] = pdfa.find_date(df, 'original_logtime', h=4)\n",
    "\n",
    "mean_daily_eating_duration(df,'float_time', ref_tbl['Start_Day'].iloc[1], ref_tbl['End_day'].iloc[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98efa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def std_daily_eating_duration(df, time_col, start_date='not_defined', end_date='not_defined'):\n",
    "    \"\"\"\n",
    "    Description:\\n\n",
    "        This function calculates the standard deviation of daily eating window, which is defined as the duration between the first and last caloric intake.\n",
    "    \n",
    "    Input:\\n\n",
    "        - df(pandas df) : food_logging data.\n",
    "        - time_col(column existed in df, string) : contains the float time data for each logging.\n",
    "        - start_date(datetime.date object) : start date of the period of calculation. If not defined, it will be automatically set to be the earliest date in df. \n",
    "        - end_date(datetime.date object) : end date of the period of calculation. If not defined, it will be automatically set to be the latest date in df.\n",
    "    \n",
    "    Output:\\n\n",
    "        - a float representing the standard deviation of daily eating window.\n",
    "        \n",
    "    Requirement:\\n\n",
    "        - 'date' column existed in the df.\n",
    "        - float time is calculated.\n",
    "    \n",
    "    Optional functions to use to have proper inputs:\n",
    "        - find_date() for date_col\n",
    "        - find_float_time() for time_col\n",
    "    \"\"\"\n",
    "    if pd.isnull(start_date) or pd.isnull(end_date):\n",
    "        return np.nan\n",
    "    if start_date=='not_defined':\n",
    "        start_date = df['date'].min()\n",
    "    if end_date=='not_defined':\n",
    "        end_date = df['date'].max()\n",
    "    df = df[(df['date']>=start_date) & (df['date']<=end_date)]\n",
    "    df = df[df['food_type'].isin(['f','b'])]\n",
    "    breakfast_time = df.groupby('date').agg(min)\n",
    "    dinner_time = df.groupby('date').agg(max)\n",
    "\n",
    "    return (dinner_time[col]-breakfast_time[col]).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f09477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.986972094736853"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# float time and date columns are required for this function\n",
    "df['float_time'] = pdfa.find_float_time(df, 'original_logtime', h=4)\n",
    "df['date'] = pdfa.find_date(df, 'original_logtime', h=4)\n",
    "\n",
    "std_daily_eating_duration(df,'float_time', ref_tbl['Start_Day'].iloc[0], ref_tbl['End_day'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd87ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def earliest_entry(df, time_col, start_date='not_defined', end_date='not_defined'):\n",
    "    \"\"\"\n",
    "    Description:\\n\n",
    "        This function calculates the earliest first calorie on any day in the study period. \n",
    "    Input:\\n\n",
    "        - df(pandas df) : food_logging data.\n",
    "        - col(column existed in df, string) : contains information of logging time in float.\n",
    "        - start_date(datetime.date object) : start date of the period of calculation. If not defined, it will be automatically set to be the earliest date in df. \n",
    "        - end_date(datetime.date object) : end date of the period of calculation. If not defined, it will be automatically set to be the latest date in df.\n",
    "    \n",
    "    Output:\\n\n",
    "        - the earliest caloric time in float on any day in the study period. \n",
    "        \n",
    "    Requirement:\\n\n",
    "        - 'date' column existed in the df.\n",
    "    \n",
    "    Optional functions to use to have proper inputs:\n",
    "        - find_date() for date_col\n",
    "        - find_float_time() for time_col\n",
    "    \"\"\"\n",
    "    # if start_date or end_date is missing, return nan\n",
    "    if pd.isnull(start_date) or pd.isnull(end_date):\n",
    "        return np.nan\n",
    "    # if there is no input on start_date or end_date, use earliest date and latest date\n",
    "    if start_date=='not_defined':\n",
    "        start_date = df['date'].min()\n",
    "    if end_date=='not_defined':\n",
    "        end_date = df['date'].max()\n",
    "        \n",
    "    df = df[(df['date']>=start_date) & (df['date']<=end_date)]\n",
    "    \n",
    "    return df[col].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe2ad82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# float time and date columns are required for this function\n",
    "earliest_entry(df,'float_time', ref_tbl['Start_Day'].iloc[0], ref_tbl['End_day'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0600649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def find_percentiles(df, time_col, percentiles, start_date='not_defined', end_date='not_defined'):\n",
    "    \"\"\"\n",
    "    Description:\\n\n",
    "        This function calculates the percentiles of the given column with specified percentiles. \n",
    "    Input:\\n\n",
    "        - df(pandas df) : food_logging data.\n",
    "        - time_col(column existed in df, string) : contains information of logging time in float.\n",
    "        - start_date(datatime.date object) : start date of the period of calculation. If not defined, it will be automatically set to be the earliest date in df. \n",
    "        - end_date(datetime.date object) : end date of the period of calculation. If not defined, it will be automatically set to be the latest date in df.\n",
    "    \n",
    "    Output:\\n\n",
    "        - a pd series data contains information of percentiles and also basic descriptive information such as count, mean, std, etc.\n",
    "        \n",
    "    Requirement:\\n\n",
    "        - 'date' column existed in the df.\n",
    "        - float time is calculated.\n",
    "    \n",
    "    Optional functions to use to have proper inputs:\n",
    "        - find_date() for date_col\n",
    "        - find_float_time() for time_col\n",
    "    \"\"\"\n",
    "    # if start_date or end_date is missing, return nan\n",
    "    if pd.isnull(start_date) or pd.isnull(end_date):\n",
    "        return np.nan\n",
    "    # if there is no input on start_date or end_date, use earliest date and latest date\n",
    "    if start_date=='not_defined':\n",
    "        start_date = df['date'].min()\n",
    "    if end_date=='not_defined':\n",
    "        end_date = df['date'].max()\n",
    "        \n",
    "    df = df[(df['date']>=start_date) & (df['date']<=end_date)]\n",
    "    return df[col].describe(percentiles=percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7d4716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     7.000000\n",
       "mean     14.857143\n",
       "std       9.821169\n",
       "min       4.500000\n",
       "2.5%      4.537500\n",
       "50%      12.500000\n",
       "97.5%    27.562500\n",
       "max      27.750000\n",
       "Name: float_time, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_percentiles(df[df['PID']=='yrt1999'], 'float_time', [.025, 0.975], ref_tbl.iloc[0]['Start_Day'], ref_tbl.iloc[0]['End_day'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20bf81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def logging_day_counts(df, start_date='not_defined', end_date='not_defined'):\n",
    "    \"\"\"\n",
    "    Description:\\n\n",
    "        This function calculates the number of days that contains any loggings. \n",
    "    Input:\\n\n",
    "        - df : food_logging data.\n",
    "        - start_date : start date of the period of calculation. If not defined, it will be automatically set to be the earliest date in df. \n",
    "        - end_date : end date of the period of calculation. If not defined, it will be automatically set to be the latest date in df.\n",
    "    \n",
    "    Output:\\n\n",
    "        - an integer that represents the number of logging days.\n",
    "        \n",
    "    Requirement:\\n\n",
    "        - 'date' column existed in the df.\n",
    "    \"\"\"\n",
    "    # if start_date or end_date is missing, return nan\n",
    "    if pd.isnull(start_date) or pd.isnull(end_date):\n",
    "        return np.nan\n",
    "    # if there is no input on start_date or end_date, use earliest date and latest date\n",
    "    if start_date=='not_defined':\n",
    "        start_date = df['date'].min()\n",
    "    if end_date=='not_defined':\n",
    "        end_date = df['date'].max()\n",
    "        \n",
    "    df = df[(df['date']>=start_date) & (df['date']<=end_date)]\n",
    "    \n",
    "    return df.date.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2da421e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging_day_counts(df[df['PID']=='yrt1999'], ref_tbl.iloc[1]['Start_Day'],ref_tbl.iloc[1]['End_day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b162dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def good_lwa_day_counts(df, window_start, window_end, min_log_num=2, min_seperation=5, buffer_time= '15 minutes',h=4, start_date='not_defined', end_date='not_defined'):\n",
    "    \"\"\"\n",
    "    Description:\\n\n",
    "        This function calculates the number of good logging days, good window days, outside window days and adherent days. Good logging day is defined as a day that the person makes at least min_log_num number of loggings and the time separation between the earliest and the latest logging are greater than min_seperation.\\n\n",
    "        A good window day is defined as a date that all the food loggings are within the assigned restricted window. An adherent day is defined as a date that is both a good logging day and a good window day.\n",
    "    Input:\\n\n",
    "        - df(pandas df): food_logging data.\n",
    "        - window_start(datetime.time object): start time of the restriction window.\n",
    "        - window_end(datetime.time object): end time of the restriction window.\n",
    "        - min_log_num(count, int): minimum number of loggings to qualify a day as a good logging day\n",
    "        - min_seperation(hours, int): minimum period of separation between earliest and latest loggings to qualify a day as a good logging day\n",
    "        - buffer_time(time in string that can be passed into pd.Timedelta()): wiggle room for to be added/subtracted on the ends of windows.\n",
    "        - h(hours, int): hours to be pushed back\n",
    "        - start_date(datetime.date object): start date of the period for calculation. If not defined, it will be automatically set to be the earliest date in df.\n",
    "        - end_date(datetime.date object): end date of the period for calculation. If not defined, it will be automatically set to be the latest date in df.\n",
    "    Output:\\n\n",
    "        - a list that represents the number of good logging days, good window days, outside window days and adherent days.\n",
    "    Requirement:\\n\n",
    "        - 'date' column existed in the df.\n",
    "        - float time is calculated.\n",
    "    \"\"\"\n",
    "    # if start_date or end_date is missing, return nan\n",
    "    if pd.isnull(start_date) or pd.isnull(end_date):\n",
    "        return [np.nan,np.nan,np.nan,np.nan], [[],[],[]]\n",
    "    \n",
    "    # if window start or window end are nan, make the windows the same as control's window time.\n",
    "    if pd.isnull(window_start):\n",
    "        window_start = datetime.time(0,0)\n",
    "    if pd.isnull(window_end):\n",
    "        window_end = datetime.time(23,59)\n",
    "        \n",
    "    # if there is no input on start_date or end_date, use earliest date and latest date\n",
    "    if start_date=='not_defined':\n",
    "        start_date = df['date'].min()\n",
    "    if end_date=='not_defined':\n",
    "        end_date = df['date'].max()\n",
    "\n",
    "    # helper function to determine a good logging\n",
    "    def good_logging(float_time_series):\n",
    "        if len(float_time_series.values) >= min_log_num and (max(float_time_series.values) - min(float_time_series.values)) >= min_seperation:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    df = df[(df['date']>=start_date) & (df['date']<=end_date)]\n",
    "    df = df[df['food_type'].isin(['f','b'])]\n",
    "    df['original_logtime'] = df['original_logtime'].dt.tz_localize(None)\n",
    "\n",
    "    buffer_time = pd.Timedelta(buffer_time).total_seconds()/3600.\n",
    "\n",
    "    in_window_count = []\n",
    "    daily_count = []\n",
    "    good_logging_count = []\n",
    "    cur_dates = df['date'].sort_values(ascending = True).unique()\n",
    "    for aday in cur_dates:\n",
    "        window_start_daily = window_start.hour+window_start.minute/60- buffer_time\n",
    "        window_end_daily = window_end.hour+window_end.minute/60 + buffer_time\n",
    "        tmp = df[df['date']==aday]\n",
    "        if (window_start == datetime.time(0,0)) and (window_end == datetime.time(23,59)):\n",
    "            in_window_count.append(tmp[(tmp['float_time']>=window_start_daily+h) & (tmp['float_time']<=window_end_daily+h)].shape[0])\n",
    "        else:\n",
    "            in_window_count.append(tmp[(tmp['float_time']>=window_start_daily) & (tmp['float_time']<=window_end_daily)].shape[0])\n",
    "        daily_count.append(df[df['date']==aday].shape[0])\n",
    "        good_logging_count.append(good_logging(df[df['date']==aday].float_time))\n",
    "\n",
    "    in_window_count = np.array(in_window_count)\n",
    "    daily_count = np.array(daily_count)\n",
    "    good_logging_count = np.array(good_logging_count)\n",
    "    good_logging_by_date = [cur_dates[i] for i, x in enumerate(good_logging_count) if x == False]\n",
    "\n",
    "    good_window_days = (in_window_count==daily_count)\n",
    "    good_window_day_counts = good_window_days.sum()\n",
    "    good_window_by_date = [cur_dates[i] for i, x in enumerate(good_window_days) if x == False]\n",
    "    \n",
    "    outside_window_days = in_window_count.size - good_window_days.sum()\n",
    "    good_logging_days = good_logging_count.sum()\n",
    "    if good_logging_count.size == 0:\n",
    "        adherent_day_counts = 0\n",
    "        adherent_days_by_date = []\n",
    "    else:\n",
    "        adherent_days = (good_logging_count & (in_window_count==daily_count))\n",
    "        adherent_days_by_date = [cur_dates[i] for i, x in enumerate(adherent_days) if x == False]\n",
    "        adherent_day_counts = adherent_days.sum()\n",
    "    \n",
    "    rows = [good_logging_days, good_window_day_counts, outside_window_days, adherent_day_counts]\n",
    "    bad_dates = (good_logging_by_date, good_window_by_date, adherent_days_by_date)\n",
    "\n",
    "    return rows, bad_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c53073c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 3, 0, 2],\n",
       " ([datetime.date(2021, 5, 15)], [], [datetime.date(2021, 5, 15)]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_lwa_day_counts(df[df['PID']=='yrt1999']\n",
    "                   , window_start=ref_tbl.iloc[4]['Eating_Window_Start']\n",
    "                   , window_end = ref_tbl.iloc[4]['Eating_Window_End']\n",
    "                   , min_log_num=2\n",
    "                   , min_seperation=5\n",
    "                   , buffer_time= pd.Timedelta('15 minutes')\n",
    "                   , start_date=ref_tbl.iloc[1]['Start_Day']\n",
    "                   , end_date=ref_tbl.iloc[1]['End_day']\n",
    "                    , h=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67fb703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def find_missing_logging_days(df, start_date='not_defined', end_date='not_defined'):\n",
    "    \"\"\"\n",
    "    Description:\\n\n",
    "        This function finds the days during which there's no logging within the period from start_date to end_date. \n",
    "    Input:\\n\n",
    "        - df(panda df): food_logging data.\n",
    "        - start_date(datetime.date object): start date of the period of calculation. If not defined, it will be automatically set to be the earliest date in df. \n",
    "        - end_date(datetime.date object): end date of the period of calculation. If not defined, it will be automatically set to be the latest date in df.\n",
    "    \n",
    "    Output:\\n\n",
    "        - a list that contains all of the dates that don't contain loggings.\n",
    "        \n",
    "    Requirement:\\n\n",
    "        - 'date' column existed in the df.\n",
    "    \"\"\"\n",
    "    # if start_date or end_date is missing, return nan\n",
    "    if pd.isnull(start_date) or pd.isnull(end_date):\n",
    "        return np.nan\n",
    "    # if there is no input on start_date or end_date, use earliest date and latest date\n",
    "    if start_date=='not_defined':\n",
    "        start_date = df['date'].min()\n",
    "    if end_date=='not_defined':\n",
    "        end_date = df['date'].max()\n",
    "        \n",
    "    df = df[(df['date']>=start_date) & (df['date']<=end_date)]\n",
    "    \n",
    "    # get all the dates between two dates\n",
    "    lst = []\n",
    "    for x in pd.date_range(start_date.date(), end_date.date(), freq='d'):\n",
    "         if x not in df['date'].unique():\n",
    "                lst.append(x.date())\n",
    "    \n",
    "    return lst\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9818885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.date(2021, 5, 18)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the date to meet the requirement\n",
    "df['original_logtime'] = pd.to_datetime(df['original_logtime'])\n",
    "df['date'] = pdfa.find_date(df, 'original_logtime', h=4)\n",
    "\n",
    "find_missing_logging_days(df[df['PID']=='yrt1999'], ref_tbl.iloc[1]['Start_Day'],ref_tbl.iloc[1]['End_day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4244dd46",
   "metadata": {},
   "source": [
    "### data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b6c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_table(food_data, ref_tbl, report_level=2, min_log_num=2, min_seperation=5, buffer_time= '15 minutes', h=4):\n",
    "    \"\"\"\n",
    "    Description:\\n\n",
    "        This is a comprehensive function that performs all of the functionalities needed.\n",
    "    \n",
    "    Input:\\n\n",
    "        - food_data(panda df): food_logging data.\n",
    "        - ref_tbl(panda df): table that contains window information and study phase information for each participant.\n",
    "        - report_level(int): whether to print out the dates of no logging days, bad logging days, bad window days and non-adherent days for each participant. 0 - no report. 1 - report no logging days. 2 - report no logging days, bad logging days, bad window days and non adherent days.\n",
    "        - h(hours): hour manipulation so that the starting and ending time for each day is more realistic.\n",
    "        - min_log_num(counts): minimum number of loggings to qualify a day as a good logging day.\n",
    "        - min_seperation(hours): minimum period of separation between earliest and latest loggings to qualify a day as a good logging day\n",
    "        - buffer_time(time in string that can be passed into pd.Timedelta()): wiggle room for to be added/subtracted on the ends of windows.\n",
    "        - h(hours): hours to be pushed back.\n",
    "        \n",
    "    \n",
    "    Output:\\n\n",
    "        - df : dataframe that has all the variables needed and has the same row number as the ref_tbl.\n",
    "        \n",
    "    Requirement:\\n\n",
    "        - food logging data is already read from all files in the directories into a dataframe, which will be passed in as the variable food_data.\n",
    "        - Columns 'Start_Day', 'End_day', 'mCC_ID', 'Eating_Window_Start', 'Eating_Window_End' existed in the ref_tbl.\n",
    "        - For eating window without restriction(HABIT or TRE not in intervention period), Eating_Window_Start is 0:00, Eating_Window_End is 23:59.\n",
    "        \n",
    "    \"\"\"\n",
    "    df = food_data.copy()\n",
    "    # preprocess to get the date and float_time column\n",
    "    df['original_logtime'] = pd.to_datetime(df['original_logtime'])\n",
    "    df['date'] = pdfa.find_date(df, 'original_logtime', h)\n",
    "    df['float_time'] = pdfa.find_float_time(df, 'original_logtime', h)\n",
    "    \n",
    "    # get study phase duration\n",
    "    result = get_phase_duration(ref_tbl)\n",
    "    \n",
    "    # reset the index of ref_tbl to avoid issues during concatenation\n",
    "    ref_tbl = ref_tbl.reset_index(drop=True)\n",
    "    \n",
    "    # loop through each row and get 'caloric_entries', 'mean_daily_eating_window', 'std_daily_eating_window', 'eariliest_entry', 'logging_day_counts',\n",
    "    # and 'good_logging_days', 'good_window_days', 'outside_window_days' and 'adherent_days' and find missing dates\n",
    "    matrix = []\n",
    "    missing_dates = {}\n",
    "    bad_dates_dic = {}\n",
    "    for index, row in ref_tbl.iterrows():\n",
    "        id_ = row['mCC_ID']\n",
    "        rows = []\n",
    "        rows.append(caloric_entries(df[df['PID']==id_], row['Start_Day'],row['End_day']))\n",
    "        rows.append(mean_daily_eating_duration(df[df['PID']==id_],'float_time', row['Start_Day'],row['End_day']))\n",
    "        rows.append(std_daily_eating_duration(df[df['PID']==id_],'float_time', row['Start_Day'],row['End_day']))\n",
    "        rows.append(earliest_entry(df[df['PID']==id_],'float_time', row['Start_Day'],row['End_day']))\n",
    "        rows.append(logging_day_counts(df[df['PID']==id_], row['Start_Day'],row['End_day']))\n",
    "\n",
    "        row_day_num, bad_dates = good_lwa_day_counts(df[df['PID']==id_]\n",
    "                                           , window_start=row['Eating_Window_Start']\n",
    "                                           , window_end = row['Eating_Window_End']\n",
    "                                           , min_log_num=min_log_num\n",
    "                                           , min_seperation=min_seperation\n",
    "                                           , buffer_time= buffer_time\n",
    "                                           , start_date=row['Start_Day']\n",
    "                                           , end_date=row['End_day']\n",
    "                                            , h=h)\n",
    "        for x in row_day_num:\n",
    "            rows.append(x)\n",
    "        bad_logging = bad_dates[0]\n",
    "        bad_window = bad_dates[1]\n",
    "        non_adherent = bad_dates[2]\n",
    "\n",
    "        if '{}_bad_logging'.format(id_) not in bad_dates_dic:\n",
    "            bad_dates_dic['{}_bad_logging'.format(id_)]=bad_logging\n",
    "            bad_dates_dic['{}_bad_window'.format(id_)]=bad_window\n",
    "            bad_dates_dic['{}_non_adherent'.format(id_)]=non_adherent\n",
    "        else:\n",
    "            bad_dates_dic['{}_bad_logging'.format(id_)]+=bad_logging\n",
    "            bad_dates_dic['{}_bad_window'.format(id_)]+=bad_window\n",
    "            bad_dates_dic['{}_non_adherent'.format(id_)]+=non_adherent\n",
    "                \n",
    "        matrix.append(rows)\n",
    "        date_lst = find_missing_logging_days(df[df['PID']==id_], row['Start_Day'],row['End_day'])\n",
    "        # only consider when the result is not nan\n",
    "        if isinstance(date_lst, list)==True:\n",
    "            if id_ in missing_dates:\n",
    "                missing_dates[id_] += date_lst\n",
    "            else:\n",
    "                missing_dates[id_] = date_lst\n",
    "\n",
    "    # create a temp dataframe\n",
    "    tmp = pd.DataFrame(matrix, columns = ['caloric_entries', 'mean_daily_eating_window', 'std_daily_eating_window', 'earliest_entry', 'logging_day_counts'\\\n",
    "                                         ,'good_logging_days', 'good_window_days', 'outside_window_days', 'adherent_days'])\n",
    "    \n",
    "    # concat these two tables\n",
    "    returned = pd.concat([ref_tbl, tmp], axis=1)\n",
    "    \n",
    "    # loop through each row and get 2.5%, 97.5%, duration mid 95% column\n",
    "    column_025 = []\n",
    "    column_975 = []\n",
    "    for index, row in ref_tbl.iterrows():\n",
    "        id_ = row['mCC_ID']\n",
    "        series = find_percentiles(df[df['PID']==id_], 'float_time', [.025, 0.975], row['Start_Day'], row['End_day'])\n",
    "        try:\n",
    "            column_025.append(series.loc['2.5%'])\n",
    "        except:\n",
    "            column_025.append(np.nan)\n",
    "        try:\n",
    "            column_975.append(series.loc['97.5%'])\n",
    "        except:\n",
    "            column_975.append(np.nan)\n",
    "    returned['2.5%'] = column_025\n",
    "    returned['97.5%'] = column_975\n",
    "    returned['duration mid 95%'] = returned['97.5%'] - returned['2.5%']\n",
    "    \n",
    "    \n",
    "    # calculate percentage for \n",
    "    for x in returned.columns:\n",
    "        if x in ['logging_day_counts','good_logging_days', 'good_window_days', 'outside_window_days', 'adherent_days']:\n",
    "            returned['%_'+x] = returned[x]/returned['phase_duration'].dt.days\n",
    "\n",
    "    # reorder the columns\n",
    "    returned = returned[['mCC_ID', 'Participant_Study_ID', 'Study Phase',\n",
    "       'Intervention group (TRE or HABIT)', 'Start_Day', 'End_day',\n",
    "       'Eating_Window_Start','Eating_Window_End', 'phase_duration',\n",
    "       'caloric_entries', 'mean_daily_eating_window', 'std_daily_eating_window',\n",
    "       'earliest_entry', '2.5%', '97.5%', 'duration mid 95%',\n",
    "       'logging_day_counts', '%_logging_day_counts', 'good_logging_days',\n",
    "        '%_good_logging_days','good_window_days', '%_good_window_days', \n",
    "        'outside_window_days','%_outside_window_days', 'adherent_days',\n",
    "       '%_adherent_days']]    \n",
    "    \n",
    "    if report_level == 0:\n",
    "        return returned\n",
    "    \n",
    "    # print out missing dates with participant's id\n",
    "    for x in missing_dates:\n",
    "        if len(missing_dates[x])>0:\n",
    "            print(\"Participant {} didn't log any food items in the following day(s):\".format(x))\n",
    "            for date in missing_dates[x]:\n",
    "                print(date)\n",
    "                \n",
    "    if report_level == 1:\n",
    "        return returned\n",
    "        \n",
    "    # print out bad logging, bad window and non-adherent dates with participant's id\n",
    "    for x in bad_dates_dic:\n",
    "        if len(bad_dates_dic[x])>0:\n",
    "            strings = x.split('_')\n",
    "            print(\"Participant {} have {} day(s) in the following day(s):\".format(strings[0], strings[1]+' '+strings[2]))\n",
    "            for date in bad_dates_dic[x]:\n",
    "                print(date)\n",
    "    \n",
    "    return returned\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be293b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant yrt1999 didn't log any food items in the following day(s):\n",
      "2021-05-18\n",
      "Participant yrt2000 didn't log any food items in the following day(s):\n",
      "2021-05-14\n",
      "2021-05-15\n",
      "2021-05-16\n",
      "2021-05-17\n",
      "2021-05-18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mCC_ID</th>\n",
       "      <th>Participant_Study_ID</th>\n",
       "      <th>Study Phase</th>\n",
       "      <th>Intervention group (TRE or HABIT)</th>\n",
       "      <th>Start_Day</th>\n",
       "      <th>End_day</th>\n",
       "      <th>Eating_Window_Start</th>\n",
       "      <th>Eating_Window_End</th>\n",
       "      <th>phase_duration</th>\n",
       "      <th>caloric_entries</th>\n",
       "      <th>...</th>\n",
       "      <th>logging_day_counts</th>\n",
       "      <th>%_logging_day_counts</th>\n",
       "      <th>good_logging_days</th>\n",
       "      <th>%_good_logging_days</th>\n",
       "      <th>good_window_days</th>\n",
       "      <th>%_good_window_days</th>\n",
       "      <th>outside_window_days</th>\n",
       "      <th>%_outside_window_days</th>\n",
       "      <th>adherent_days</th>\n",
       "      <th>%_adherent_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yrt1999</td>\n",
       "      <td>2</td>\n",
       "      <td>S-REM</td>\n",
       "      <td>TRE</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>2021-05-14</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>23:59:00</td>\n",
       "      <td>3 days</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yrt1999</td>\n",
       "      <td>2</td>\n",
       "      <td>T3-INT</td>\n",
       "      <td>TRE</td>\n",
       "      <td>2021-05-15</td>\n",
       "      <td>2021-05-18</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>4 days</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yrt2000</td>\n",
       "      <td>3</td>\n",
       "      <td>T3-INT</td>\n",
       "      <td>TRE</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>2021-05-14</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>3 days</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yrt2000</td>\n",
       "      <td>3</td>\n",
       "      <td>T3-INT</td>\n",
       "      <td>TRE</td>\n",
       "      <td>2021-05-15</td>\n",
       "      <td>2021-05-18</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>4 days</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yrt2001</td>\n",
       "      <td>4</td>\n",
       "      <td>T12-A</td>\n",
       "      <td>TRE</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mCC_ID  Participant_Study_ID Study Phase  \\\n",
       "0  yrt1999                     2       S-REM   \n",
       "1  yrt1999                     2      T3-INT   \n",
       "2  yrt2000                     3      T3-INT   \n",
       "3  yrt2000                     3      T3-INT   \n",
       "4  yrt2001                     4       T12-A   \n",
       "\n",
       "  Intervention group (TRE or HABIT)  Start_Day    End_day Eating_Window_Start  \\\n",
       "0                               TRE 2021-05-12 2021-05-14            00:00:00   \n",
       "1                               TRE 2021-05-15 2021-05-18            08:00:00   \n",
       "2                               TRE 2021-05-12 2021-05-14            08:00:00   \n",
       "3                               TRE 2021-05-15 2021-05-18            08:00:00   \n",
       "4                               TRE        NaT        NaT                 NaN   \n",
       "\n",
       "  Eating_Window_End phase_duration  caloric_entries  ...  logging_day_counts  \\\n",
       "0          23:59:00         3 days              7.0  ...                 3.0   \n",
       "1          18:00:00         4 days              8.0  ...                 3.0   \n",
       "2          16:00:00         3 days              4.0  ...                 2.0   \n",
       "3          16:00:00         4 days              0.0  ...                 0.0   \n",
       "4               NaN            NaT              NaN  ...                 NaN   \n",
       "\n",
       "   %_logging_day_counts  good_logging_days  %_good_logging_days  \\\n",
       "0              1.000000                2.0             0.666667   \n",
       "1              0.750000                2.0             0.500000   \n",
       "2              0.666667                0.0             0.000000   \n",
       "3              0.000000                0.0             0.000000   \n",
       "4                   NaN                NaN                  NaN   \n",
       "\n",
       "   good_window_days  %_good_window_days  outside_window_days  \\\n",
       "0               3.0            1.000000                  0.0   \n",
       "1               1.0            0.250000                  2.0   \n",
       "2               1.0            0.333333                  1.0   \n",
       "3               0.0            0.000000                  0.0   \n",
       "4               NaN                 NaN                  NaN   \n",
       "\n",
       "   %_outside_window_days  adherent_days  %_adherent_days  \n",
       "0               0.000000            2.0         0.666667  \n",
       "1               0.500000            1.0         0.250000  \n",
       "2               0.333333            0.0         0.000000  \n",
       "3               0.000000            0.0         0.000000  \n",
       "4                    NaN            NaN              NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = make_table(pd.read_csv('data/col_test_data/toy_data_2000.csv')\\\n",
    "                      , pd.read_excel('data/col_test_data/toy_data_17May2021.xlsx'), report_level = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff1ae86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mCC_ID                                           yrt2000\n",
       "Participant_Study_ID                                   3\n",
       "Study Phase                                       T3-INT\n",
       "Intervention group (TRE or HABIT)                    TRE\n",
       "Start_Day                            2021-05-12 00:00:00\n",
       "End_day                              2021-05-14 00:00:00\n",
       "Eating_Window_Start                             08:00:00\n",
       "Eating_Window_End                               16:00:00\n",
       "phase_duration                           3 days 00:00:00\n",
       "caloric_entries                                      4.0\n",
       "mean_daily_eating_window                             4.0\n",
       "std_daily_eating_window                              0.0\n",
       "earliest_entry                                       4.5\n",
       "2.5%                                                 4.8\n",
       "97.5%                                               12.2\n",
       "duration mid 95%                                     7.4\n",
       "logging_day_counts                                   2.0\n",
       "%_logging_day_counts                            0.666667\n",
       "good_logging_days                                    0.0\n",
       "%_good_logging_days                                  0.0\n",
       "good_window_days                                     1.0\n",
       "%_good_window_days                              0.333333\n",
       "outside_window_days                                  1.0\n",
       "%_outside_window_days                           0.333333\n",
       "adherent_days                                        0.0\n",
       "%_adherent_days                                      0.0\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7c761c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mCC_ID                                           yrt1999\n",
       "Participant_Study_ID                                   2\n",
       "Study Phase                                       T3-INT\n",
       "Intervention group (TRE or HABIT)                    TRE\n",
       "Start_Day                            2021-05-15 00:00:00\n",
       "End_day                              2021-05-18 00:00:00\n",
       "Eating_Window_Start                             08:00:00\n",
       "Eating_Window_End                               18:00:00\n",
       "phase_duration                           4 days 00:00:00\n",
       "caloric_entries                                      8.0\n",
       "mean_daily_eating_window                        8.666667\n",
       "std_daily_eating_window                         8.504901\n",
       "earliest_entry                                       7.5\n",
       "2.5%                                                 7.7\n",
       "97.5%                                               23.9\n",
       "duration mid 95%                                    16.2\n",
       "logging_day_counts                                   3.0\n",
       "%_logging_day_counts                                0.75\n",
       "good_logging_days                                    2.0\n",
       "%_good_logging_days                                  0.5\n",
       "good_window_days                                     1.0\n",
       "%_good_window_days                                  0.25\n",
       "outside_window_days                                  2.0\n",
       "%_outside_window_days                                0.5\n",
       "adherent_days                                        1.0\n",
       "%_adherent_days                                     0.25\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50e5f13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
